{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1G3rcmRmES0K4iWZ4zqBObSyQ-0KOYwmZ",
      "authorship_tag": "ABX9TyNcob32uld46dtQhZnFSuY+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dat-291020/BTLAI/blob/main/DA_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CphhhzreERO6"
      },
      "outputs": [],
      "source": [
        "#/content/drive/MyDrive/DATN/Source Code/data_4/data.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def load_csv(data_dir, features = []):\n",
        "    df = pd.read_csv(data_dir)\n",
        "    if len(features) > 0:\n",
        "        df = df[features]\n",
        "    return df\n",
        "\n",
        "def split(df, features, scaler, valid_date, test_date, end_date, time_lag=1, freq='D'):\n",
        "    X = df[features]\n",
        "    X[features] = scaler.transform(X)\n",
        "    train = X.copy()[X.index < valid_date]\n",
        "    train = window_generate(train, features, time_lag=time_lag, freq=freq)\n",
        "    valid = X.copy()[(X.index < test_date) & (X.index >= valid_date)]\n",
        "    valid = window_generate(valid, features, time_lag=time_lag, freq=freq)\n",
        "    test = X.copy()[(X.index < end_date) & (X.index >= test_date)]\n",
        "    test = window_generate(test, features, time_lag=time_lag, freq=freq)\n",
        "    return train, valid, test\n",
        "\n",
        "def split_y(df, targets, scaler, valid_date, test_date, end_date, horizon=1, freq='D'):\n",
        "    X = df[targets]\n",
        "    X[targets] = scaler.transform(X)\n",
        "    m = targets\n",
        "    for i in range(len(targets)):\n",
        "        m[i]=targets[i]+\"+\"+str(horizon)\n",
        "    X=X.set_axis(m, axis='columns')\n",
        "    train = X.copy()[X.index < valid_date]\n",
        "    train = train.shift(periods=-horizon, freq=freq)\n",
        "    valid = X.copy()[(X.index < test_date) & (X.index >= valid_date)]\n",
        "    valid = valid.shift(periods=-horizon, freq=freq)\n",
        "    test = X.copy()[(X.index < end_date) & (X.index >= test_date)]\n",
        "    test = test.shift(periods=-horizon, freq=freq)\n",
        "    return train, valid, test\n",
        "\n",
        "def window_generate(df, features, time_lag, freq='D'):\n",
        "    data = df.copy()[features]\n",
        "    result = pd.DataFrame()\n",
        "    for i in range(-time_lag+1, 1):\n",
        "        columns = []\n",
        "        data_i = data.shift(periods=-i, freq=freq)\n",
        "        for j in range(len(features)):\n",
        "            columnsj = data.columns[j] + '_%d'%(i)\n",
        "            columns.append(columnsj)\n",
        "        data_i = data_i.set_axis(columns, axis=1, inplace=False)\n",
        "        result = pd.concat([result, data_i], axis = 1)\n",
        "    return result\n",
        "\n",
        "def power_set(seq):\n",
        "    if len(seq)<=1:\n",
        "        yield seq\n",
        "        yield []\n",
        "    else:\n",
        "        for item in power_set(seq[1:]):\n",
        "            yield [seq[0]]+item\n",
        "            yield item"
      ],
      "metadata": {
        "id": "OHniU_-5cFJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, GRU, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.layers import Flatten, Activation, Reshape, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
        "\n",
        "def normal_lstm(features_count = 1, lag_time = 1):\n",
        "    x = Input(shape = (lag_time, features_count))\n",
        "    lstm = LSTM(32)(x)\n",
        "    dense1 = Dense(16)(lstm)\n",
        "    output = Dense(1)(dense1)\n",
        "    model = Model(inputs = x, outputs = output)\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mape', 'mae'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def stack_lstm(features_count = 1, lag_time = 1):\n",
        "    x = Input(shape = (lag_time, features_count))\n",
        "    lstm1 = LSTM(64, return_sequences = True)(x)\n",
        "    lstm2 = LSTM(32)(lstm1)\n",
        "    dense1 = Dense(64, name = 'spec_out0')(lstm2)\n",
        "    output = Dense(1)(dense1)\n",
        "    model = Model(inputs = x, outputs = output)\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mape', 'mae'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def mtl_mtv_lstm(features_count, addition_features, lag_time, batch_size=32):\n",
        "    x = Input(shape = (lag_time, features_count))\n",
        "    lstm1 = LSTM(16, return_sequences = True)(x)\n",
        "    lstm2 = LSTM(32, return_sequences = True)(lstm1)\n",
        "    shared_dense = Dense(64)(lstm2)\n",
        "    # main task\n",
        "    sub1 = GRU(units=(lag_time*addition_features), name=\"task1\")(shared_dense)\n",
        "    #addition task for main imf\n",
        "    sub2 = LSTM(units=16, name=\"task2\")(shared_dense)\n",
        "    sub3 = LSTM(units=16, name=\"task3\")(shared_dense)\n",
        "    # merge sub1 with addition input imfs\n",
        "    sub1 = Reshape((lag_time, addition_features))(sub1)\n",
        "    addition_input = Input(shape=(lag_time, addition_features), name='add_input')\n",
        "    concate = Concatenate(axis=-1)([sub1, addition_input])\n",
        "    #perform mtl\n",
        "    out1 = Dense(8, name=\"spec_out1\")(concate)\n",
        "    out1 = Flatten()(out1)\n",
        "    out1 = Dense(1, name=\"out1\")(out1)\n",
        "\n",
        "    out2 = Dense(8, name=\"spec_out2\")(sub2)\n",
        "    out2 = Dense(1, name=\"out2\")(out2)\n",
        "\n",
        "    out3 = Dense(1, name=\"spec_out3\")(sub3)\n",
        "    out3 = Dense(1, name=\"out3\")(out3)\n",
        "\n",
        "    outputs = [out1, out2, out3]\n",
        "    # define model\n",
        "    model = Model(inputs = [x, addition_input], outputs = outputs)\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mape', 'mae'], loss_weights=[0.5, 0.01, 0.01])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def model_mtl_mtv(horizon=1, nb_train_samples=512, batch_size=32, \n",
        "                  feature_count=11, lag_time=6, auxiliary_feature_count=12):\n",
        "\n",
        "    x = Input(shape=(lag_time, feature_count), name=\"input_layer\")\n",
        "\n",
        "    lstm1 = GRU(16, return_sequences=True)(x)\n",
        "    # lstm2 = GRU(32, return_sequences=True)(mp)\n",
        "    lstm2 = GRU(32, return_sequences=True)(lstm1)\n",
        "\n",
        "    shared_dense = Dense(64, name=\"shared_layer\")(lstm2)\n",
        "\n",
        "    ## sub1 is main task; units = reshape dimension multiplication\n",
        "    sub1 = GRU(units=(lag_time*auxiliary_feature_count), name=\"task1\")(shared_dense)\n",
        "    sub2 = GRU(units=16, name=\"task2\")(shared_dense)\n",
        "    sub3 = GRU(units=16, name=\"task3\")(shared_dense)\n",
        "\n",
        "    sub1 = Reshape((lag_time, auxiliary_feature_count))(sub1)\n",
        "    auxiliary_input = Input(shape=(lag_time, auxiliary_feature_count), name='aux_input')\n",
        "\n",
        "    concate = Concatenate(axis=-1)([sub1, auxiliary_input])\n",
        "    # out1_gp = Dense(1, name=\"out1_gp\")(sub1)\n",
        "    out1 = Dense(8, name=\"spec_out1\")(concate)\n",
        "    out1 = Flatten()(out1)\n",
        "    out1 = Dense(1, name=\"out1\")(out1)\n",
        "\n",
        "    out2 = Dense(8, name=\"spec_out2\")(sub2)\n",
        "    out2 = Dense(1, name=\"out2\")(out2)\n",
        "\n",
        "    out3 = Dense(1, name=\"spec_out3\")(sub3)\n",
        "    out3 = Dense(1, name=\"out3\")(out3)\n",
        "\n",
        "    outputs = [out1, out2, out3]\n",
        "\n",
        "    model = Model(inputs=[x, auxiliary_input], outputs=outputs)\n",
        "\n",
        "    # adam optimizsor is good\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mape', 'mae'], loss_weights=[0.5, 0.01, 0.01])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def mtl_mtv_GRU(horizon=1, nb_train_samples=512, batch_size=32, targets=[], \n",
        "                  feature_count=11, lag_time=6, auxiliary_feature_count=12):\n",
        "    x = Input(shape=(lag_time, feature_count), name=\"input_layer\")\n",
        "\n",
        "    lstm1 = GRU(16, return_sequences=True)(x)\n",
        "    # lstm2 = GRU(32, return_sequences=True)(mp)\n",
        "    lstm2 = GRU(32, return_sequences=True)(lstm1)\n",
        "\n",
        "    shared_dense = Dense(64, name=\"shared_layer\")(lstm2)\n",
        "\n",
        "    ## sub1 is main task; units = reshape dimension multiplication\n",
        "    sub = []\n",
        "    for i in range(len(targets)):\n",
        "        if i==0:\n",
        "            subi = GRU(units=(lag_time*auxiliary_feature_count), name=\"task0\")(shared_dense)\n",
        "        else:\n",
        "            subi = GRU(units=16, name=\"task\"+str(i))(shared_dense)\n",
        "        sub.append(subi)\n",
        "\n",
        "    sub[0] = Reshape((lag_time, auxiliary_feature_count))(sub[0])\n",
        "    auxiliary_input = Input(shape=(lag_time, auxiliary_feature_count), name='aux_input')\n",
        "\n",
        "    concate = Concatenate(axis=-1)([sub[0], auxiliary_input])\n",
        "    # out1_gp = Dense(1, name=\"out1_gp\")(sub1)\n",
        "    out1 = Dense(8, name=\"spec_out0\")(concate)\n",
        "    out1 = Flatten()(out1)\n",
        "    out1 = Dense(1, name=\"out0\")(out1)\n",
        "    \n",
        "    out=[]\n",
        "    out.append(out1)\n",
        "    for i in range(1, len(targets)):\n",
        "        outi = Dense(8, name=\"spec_out\"+str(i))(sub[i])\n",
        "        outi = Dense(1, name=\"out\"+str(i))(outi)\n",
        "        out.append(outi)\n",
        "\n",
        "    outputs = out\n",
        "\n",
        "    model = Model(inputs=[x, auxiliary_input], outputs=outputs)\n",
        "    \n",
        "    weights=[]\n",
        "    for i in range(len(out)):\n",
        "        if i==0:\n",
        "            weights.append(0.5)\n",
        "        else:\n",
        "            weights.append(0.1)\n",
        "\n",
        "    # adam optimizsor is good\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mape', 'mae'], loss_weights=weights)\n",
        "    # model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "LHMgWjeCcP4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "abc\n"
      ],
      "metadata": {
        "id": "AdkJDHr9n_FD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from preprocessing.read import load_csv, window_generate, split, split_y, power_set\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LassoLars\n",
        "#from model.model import normal_lstm, stack_lstm, mtl_mtv_lstm, model_mtl_mtv, mtl_mtv_GRU\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score, mean_absolute_error, explained_variance_score\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Model\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import PredefinedSplit, TimeSeriesSplit\n"
      ],
      "metadata": {
        "id": "oK2WCWjDnE0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data and set the datetime index for data frame\n",
        "datadir = '/content/drive/MyDrive/DATN/Source Code/data_4/data.csv'\n",
        "features = []\n",
        "data = load_csv(datadir, features = features)\n",
        "data = data.set_index(pd.to_datetime(data['date'], format='%m/%d/%Y'))\n",
        "data = data.drop(['date'], axis=1)\n",
        "data = data.dropna()\n"
      ],
      "metadata": {
        "id": "erwbwikCn7ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "atxcJ_ghBYpL",
        "outputId": "b4452953-5d75-43f5-f12f-0123fa46e0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              x1    x2    x3         y\n",
              "date                                  \n",
              "1994-01-01  2007   897  2118   4653.47\n",
              "1994-01-02  2534  2161  1752  24191.18\n",
              "1994-01-03  2085  1728  1975  19187.24\n",
              "1994-01-04   502  1184  2445  19454.29\n",
              "1994-01-05  1233   581  1087  14488.55"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68b933fa-6695-4b73-86d0-65468e6adb7d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1994-01-01</th>\n",
              "      <td>2007</td>\n",
              "      <td>897</td>\n",
              "      <td>2118</td>\n",
              "      <td>4653.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994-01-02</th>\n",
              "      <td>2534</td>\n",
              "      <td>2161</td>\n",
              "      <td>1752</td>\n",
              "      <td>24191.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994-01-03</th>\n",
              "      <td>2085</td>\n",
              "      <td>1728</td>\n",
              "      <td>1975</td>\n",
              "      <td>19187.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994-01-04</th>\n",
              "      <td>502</td>\n",
              "      <td>1184</td>\n",
              "      <td>2445</td>\n",
              "      <td>19454.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994-01-05</th>\n",
              "      <td>1233</td>\n",
              "      <td>581</td>\n",
              "      <td>1087</td>\n",
              "      <td>14488.55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68b933fa-6695-4b73-86d0-65468e6adb7d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68b933fa-6695-4b73-86d0-65468e6adb7d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68b933fa-6695-4b73-86d0-65468e6adb7d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# preparing the train, valid and test data\n",
        "## set the milestone for dividing data by time\n",
        "## đặt các mốc thời gian để chia dữ liệu thành train/validatate/test\n",
        "valid_date = \"1999-01-01 00:00:00\"\n",
        "test_date = \"2001-01-01 00:00:00\"\n",
        "end_date = \"2003-01-01 00:00:00\"\n",
        "## set the lag time and horizon\n",
        "LAG = 3\n",
        "HORIZON = 1\n",
        "## data scaler (công cụ chuẩn hóa dữ liệu)\n",
        "X_scaler = StandardScaler()\n",
        "y_scaler = StandardScaler()\n",
        "main_target_scaler = StandardScaler()\n",
        "\n",
        "result = pd.DataFrame()\n",
        "result[['algorithm', 'LAG', 'Horizon', 'rmse', 'mae', 'r2', 'nse']] =[\"\",\"\",\"\",\"\",\"\",\"\",\"\"]"
      ],
      "metadata": {
        "id": "oypyUmfEoST7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "\n",
        "X_scaler = StandardScaler()\n",
        "y_scaler = StandardScaler()\n",
        "main_target_scaler = StandardScaler()\n",
        "\n",
        "input_features = data.columns[:-1] # tất cả các cột trừ cột y\n",
        "targets = [data.columns[-1]] # cột y\n",
        "\n",
        "X = data[input_features]\n",
        "y = data[targets]\n",
        "\n",
        "## tạo train data\n",
        "X_train = X.copy().loc[X.index < valid_date]\n",
        "y_train = y.copy().loc[y.index < valid_date]\n",
        "\n",
        "# fit công cụ chuẩn hóa theo dữ liệu train\n",
        "X_scaler.fit(X_train)\n",
        "y_scaler.fit(y_train)\n",
        "main_target_scaler.fit(y_train[targets[0]].values.reshape(-1,1))\n",
        "\n",
        "# dùng hàm tự định nghĩa split (trong utils/read.py) để chia dữ liệu thành\n",
        "# train/valid/test data, đồng thời tạo các chuỗi dữ liệu độ dài LAG để phục vụ dự báo\n",
        "X_tr, X_v, X_t = split(data, input_features, X_scaler, \n",
        "                                 valid_date, test_date, end_date, time_lag=LAG, freq='D')\n",
        "y_tr, y_v, y_t = split_y(data, targets, y_scaler, \n",
        "                                 valid_date, test_date, end_date, horizon=HORIZON, freq='D')\n",
        "\n",
        "# =========================================================="
      ],
      "metadata": {
        "id": "1N1MxO_iqbuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vì lstm cần cả train, valid và test nên thực hiện như thế này\n",
        "train = pd.concat([X_tr, y_tr], axis=1) # gộp chung dữ liệu đầu vào và dãy đầu ra\n",
        "train = train.loc[:,~train.columns.duplicated()].copy()#loại dữ liệu lặp\n",
        "train = train.dropna()#loại các dòng có ô trống\n",
        "\n",
        "valid = pd.concat([X_v, y_v], axis=1)\n",
        "valid = valid.loc[:,~valid.columns.duplicated()].copy()\n",
        "valid = valid.dropna()\n",
        "\n",
        "test = pd.concat([X_t, y_t], axis=1)\n",
        "test = test.loc[:,~test.columns.duplicated()].copy()\n",
        "test = test.dropna()\n",
        "\n",
        "in_features = X_tr.columns\n",
        "out_features = y_tr.columns\n",
        "\n",
        "# train, valid, test for lstm\n",
        "Xtrain = train[in_features].values\n",
        "Xtrain = Xtrain.reshape(Xtrain.shape[0], LAG, len(input_features))\n",
        "ytrain = []\n",
        "for feature in out_features:\n",
        "    ytrain.append(train[feature].values.reshape(-1,1))\n",
        "\n",
        "Xvalid = valid[in_features].values\n",
        "Xvalid = Xvalid.reshape(Xvalid.shape[0], LAG, len(input_features))\n",
        "yvalid = []\n",
        "for feature in out_features:\n",
        "    yvalid.append(valid[feature].values.reshape(-1,1))\n",
        "\n",
        "Xtest = test[in_features].values\n",
        "Xtest = Xtest.reshape(Xtest.shape[0], LAG, len(input_features))\n",
        "ytest = []\n",
        "for feature in out_features:\n",
        "    ytest.append(test[feature].values.reshape(-1,1))\n",
        "\n",
        "# Train, Test for Lassor, RF, SVR...\n",
        "## làm riêng vì với các thuật toán này không cần validate data\n",
        "XTrain = np.concatenate([Xtrain.reshape(-1, len(in_features)), \n",
        "                          Xvalid.reshape(-1, len(in_features))], axis=0)\n",
        "XTest = Xtest.reshape(-1, len(in_features))\n",
        "yTrain = np.concatenate([ytrain[0], yvalid[0]], axis=0).ravel()\n",
        "yTest = ytest[0].ravel()\n",
        "\n",
        "# ==========================================================\n",
        "\n",
        "# nash-sutcliffe efficiency\n",
        "def nse(targets,predictions):\n",
        "    return 1-(np.sum((targets-predictions)**2)/np.sum((targets-np.mean(predictions))**2))\n",
        "\n",
        "# ==========================================================\n",
        "\n",
        "## gọi công cụ chia dữ liệu để chia 5 fold với mỗi fold có cỡ test = 365\n",
        "cv = TimeSeriesSplit(n_splits=5, test_size=300)"
      ],
      "metadata": {
        "id": "Z_FHln1bqtPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LASSO\n",
        "## tạo vùng cho các tham số để lặp và chọn tham số tốt nhất\n",
        "alpha_range = np.linspace(0, 0.3, 31)\n",
        "lasso_param_grid = dict(alpha = alpha_range)\n",
        "## gọi hàm chọn tham số (GridSearchCV)\n",
        "grid_lasso = GridSearchCV(LassoLars(), param_grid=lasso_param_grid, cv=cv,\n",
        "                          scoring = 'neg_mean_squared_error',\n",
        "                          verbose = 0)\n",
        "## fit hàm chọn tham số với dữ liệu\n",
        "grid_lasso.fit(XTrain, yTrain)\n",
        "## trả kết quả\n",
        "print(\"The best parameters of LassorLars are %s with a score of %0.2f\"\n",
        "    % (grid_lasso.best_params_, grid_lasso.best_score_))\n",
        "## gọi mô hình dự báo\n",
        "model_lasso = LassoLars(alpha=grid_lasso.best_params_['alpha'], normalize=False)\n",
        "## dự báo\n",
        "yPredLasso = model_lasso.fit(XTrain, yTrain).predict(XTest)\n",
        "## đảo ngược chuẩn hóa để đưa mục tiêu dự báo về giá trị ban đầu\n",
        "y_test_lasso = main_target_scaler.inverse_transform(yTest.reshape(-1,1))\n",
        "y_pred_lasso = main_target_scaler.inverse_transform(yPredLasso.reshape(-1,1))\n",
        "## các yếu tố đánh giá\n",
        "print('lasso')\n",
        "print('rmse: ' + str(mean_squared_error(y_test_lasso, y_pred_lasso, squared=False)))\n",
        "print('r2: '+ str(r2_score(y_test_lasso, y_pred_lasso)))\n",
        "print('mae: ' + str(mean_absolute_error(y_test_lasso, y_pred_lasso)))\n",
        "print('mape: '+ str(mean_absolute_percentage_error(y_test_lasso, y_pred_lasso)))\n",
        "print('nse: ' + str(nse(y_test_lasso, y_pred_lasso)))\n",
        "## thêm kq vào dataframe result\n",
        "result.loc[result.shape[0]] = ['LASSO', LAG, HORIZON,\n",
        "                               mean_squared_error(y_test_lasso, y_pred_lasso, squared=False),\n",
        "                               mean_absolute_error(y_test_lasso, y_pred_lasso),\n",
        "                               r2_score(y_test_lasso, y_pred_lasso),\n",
        "                               nse(y_test_lasso, y_pred_lasso)]\n"
      ],
      "metadata": {
        "id": "s-jvlHrdqybL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# svr\n",
        "C_range = np.logspace(-3, 3, 7)\n",
        "gamma_range = np.logspace(-5, 2, 8)\n",
        "param_grid = dict(gamma=gamma_range, C=C_range)\n",
        "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv,\n",
        "                    scoring = 'neg_mean_absolute_percentage_error',\n",
        "                    verbose=0)\n",
        "grid.fit(XTrain, yTrain)\n",
        "\n",
        "print(\"The best parameters are %s with a score of %0.2f\"\n",
        "    % (grid.best_params_, grid.best_score_))\n",
        "\n",
        "model_svr = SVR(kernel='rbf', C=grid.best_params_['C'], \n",
        "          gamma = grid.best_params_['gamma'])\n",
        "\n",
        "yPredSVR = model_svr.fit(XTrain, yTrain).predict(XTest)\n",
        "y_test_svr = main_target_scaler.inverse_transform(yTest.reshape(-1,1))\n",
        "y_pred_svr = main_target_scaler.inverse_transform(yPredSVR.reshape(-1,1))\n",
        "\n",
        "print('svr')\n",
        "print('rmse: ' + str(mean_squared_error(y_test_svr, y_pred_svr, squared=False)))\n",
        "print('r2: '+ str(r2_score(y_test_svr, y_pred_svr)))\n",
        "print('mae: ' + str(mean_absolute_error(y_test_svr, y_pred_svr)))\n",
        "print('mape: '+ str(mean_absolute_percentage_error(y_test_svr, y_pred_svr)))\n",
        "print('nse: ' + str(nse(y_test_svr, y_pred_svr)))\n",
        "\n",
        "result.loc[result.shape[0]] = ['SVR', LAG, HORIZON,\n",
        "                               mean_squared_error(y_test_svr, y_pred_svr, squared=False),\n",
        "                               mean_absolute_error(y_test_svr, y_pred_svr),\n",
        "                               r2_score(y_test_svr, y_pred_svr),\n",
        "                               nse(y_test_svr, y_pred_svr)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH-cASyurLjv",
        "outputId": "aefb94f5-07e8-44be-f96a-9f4f00a9f2c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best parameters are {'C': 0.001, 'gamma': 0.1} with a score of -1.09\n",
            "svr\n",
            "rmse: 3446.8307620108403\n",
            "r2: -0.1644553390955863\n",
            "mae: 2781.2825852332303\n",
            "mape: 0.12141039838292514\n",
            "nse: 0.11222913780452226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rf\n",
        "n_estimators_range = [100, 200, 500, 1000]\n",
        "max_depth_range = np.array(range(5, 25, 5))\n",
        "rf_param_grid = dict(n_estimators=n_estimators_range, max_depth=max_depth_range)\n",
        "\n",
        "grid_rf = GridSearchCV(RandomForestRegressor(), param_grid=rf_param_grid, cv=cv,\n",
        "                    scoring = 'neg_mean_squared_error',  verbose=0)\n",
        "grid_rf.fit(XTrain, yTrain)\n",
        "print(\"The best parameters of randomforest are %s with a score of %0.2f\"\n",
        "    % (grid_rf.best_params_, grid_rf.best_score_))\n",
        "\n",
        "model_rf = RandomForestRegressor(n_estimators=grid_rf.best_params_['n_estimators'],\n",
        "                                 max_depth=grid_rf.best_params_['max_depth'])\n",
        "y_pred_rf = model_rf.fit(XTrain, yTrain).predict(XTest)\n",
        "y_test_rf = main_target_scaler.inverse_transform(yTest.reshape(-1,1))\n",
        "y_pred_rf = main_target_scaler.inverse_transform(y_pred_rf.reshape(-1,1))\n",
        "\n",
        "print('rf')\n",
        "print('rmse: ' + str(mean_squared_error(y_test_rf, y_pred_rf, squared=False)))\n",
        "print('r2: '+ str(r2_score(y_test_rf, y_pred_rf)))\n",
        "print('mae: ' + str(mean_absolute_error(y_test_rf, y_pred_rf)))\n",
        "print('mape: '+ str(mean_absolute_percentage_error(y_test_rf, y_pred_rf)))\n",
        "print('nse: ' + str(nse(y_test_rf, y_pred_rf)))\n",
        "\n",
        "result.loc[result.shape[0]] = ['RF', LAG, HORIZON,\n",
        "                               mean_squared_error(y_test_rf, y_pred_rf, squared=False),\n",
        "                               mean_absolute_error(y_test_rf, y_pred_rf),\n",
        "                               r2_score(y_test_rf, y_pred_rf),\n",
        "                               nse(y_test_rf, y_pred_rf)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiZEtpGDrTpM",
        "outputId": "60e3c534-0208-4197-85ed-56b2d25b2477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best parameters of randomforest are {'max_depth': 20, 'n_estimators': 1000} with a score of -0.15\n",
            "rf\n",
            "rmse: 1953.3097392390073\n",
            "r2: 0.6260400035929276\n",
            "mae: 1850.6891976224567\n",
            "mape: 0.08487467870720829\n",
            "nse: 0.7200267206918238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#lstm\n",
        "## gọi các công cụ hỗ trợ\n",
        "earlystop = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
        "file_path = 'checkpoint/weights-improvement-{epoch:02d}.hdf5'\n",
        "checkpoint = ModelCheckpoint(monitor=\"val_loss\",\n",
        "                              filepath=file_path,\n",
        "                              verbose=0,\n",
        "                              save_weight_only=True,\n",
        "                              save_best_only=True)\n",
        "## gọi hàm tự định nghĩa để khai báo mô hình lstm (trong model/model.py)\n",
        "model_lstm = stack_lstm(features_count=len(input_features), lag_time=LAG)\n",
        "## train\n",
        "model_lstm.fit(Xtrain, ytrain[0], \n",
        "          batch_size=32, \n",
        "          epochs=500, \n",
        "          validation_data=(Xvalid, yvalid[0]),\n",
        "          callbacks=[earlystop, checkpoint],\n",
        "          verbose = 2)\n",
        "## dự báo\n",
        "y_pred_lstm = model_lstm.predict(Xtest)\n",
        "y_test_lstm = main_target_scaler.inverse_transform(ytest[0].reshape(-1,1))\n",
        "y_pred_lstm = main_target_scaler.inverse_transform(y_pred_lstm.reshape(-1,1))\n",
        "\n",
        "print('lstm')\n",
        "print('rmse: ' + str(mean_squared_error(y_test_lstm, y_pred_lstm, squared=False)))\n",
        "print('r2: '+ str(r2_score(y_test_lstm, y_pred_lstm)))\n",
        "print('mae: ' + str(mean_absolute_error(y_test_lstm, y_pred_lstm)))\n",
        "print('mape: '+ str(mean_absolute_percentage_error(y_test_lstm, y_pred_lstm)))\n",
        "print('nse: ' + str(nse(y_test_lstm, y_pred_lstm)))\n",
        "\n",
        "result.loc[result.shape[0]] = ['lstm', LAG, HORIZON,\n",
        "                               mean_squared_error(y_test_lstm, y_pred_lstm, squared=False),\n",
        "                               mean_absolute_error(y_test_lstm, y_pred_lstm),\n",
        "                               r2_score(y_test_lstm, y_pred_lstm),\n",
        "                               nse(y_test_lstm, y_pred_lstm)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlmZJeLYrc66",
        "outputId": "1760beb4-c956-4830-a012-267ac0142c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 3, 3)]            0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 3, 64)             17408     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 32)                12416     \n",
            "                                                                 \n",
            " spec_out0 (Dense)           (None, 64)                2112      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,001\n",
            "Trainable params: 32,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "57/57 - 6s - loss: 0.8649 - mse: 0.8649 - mape: 125.1640 - mae: 0.7592 - val_loss: 0.6179 - val_mse: 0.6179 - val_mape: 287.4534 - val_mae: 0.6297 - 6s/epoch - 110ms/step\n",
            "Epoch 2/500\n",
            "57/57 - 0s - loss: 0.1469 - mse: 0.1469 - mape: 85.6526 - mae: 0.2736 - val_loss: 0.1658 - val_mse: 0.1658 - val_mape: 307.2810 - val_mae: 0.3951 - 409ms/epoch - 7ms/step\n",
            "Epoch 3/500\n",
            "57/57 - 0s - loss: 0.0334 - mse: 0.0334 - mape: 65.7097 - mae: 0.1558 - val_loss: 0.1901 - val_mse: 0.1901 - val_mape: 311.1917 - val_mae: 0.4272 - 411ms/epoch - 7ms/step\n",
            "Epoch 4/500\n",
            "57/57 - 0s - loss: 0.0328 - mse: 0.0328 - mape: 65.8424 - mae: 0.1548 - val_loss: 0.1950 - val_mse: 0.1950 - val_mape: 311.5044 - val_mae: 0.4326 - 386ms/epoch - 7ms/step\n",
            "Epoch 5/500\n",
            "57/57 - 0s - loss: 0.0329 - mse: 0.0329 - mape: 64.1420 - mae: 0.1546 - val_loss: 0.1778 - val_mse: 0.1778 - val_mape: 300.4553 - val_mae: 0.4120 - 407ms/epoch - 7ms/step\n",
            "Epoch 6/500\n",
            "57/57 - 0s - loss: 0.0322 - mse: 0.0322 - mape: 62.4959 - mae: 0.1528 - val_loss: 0.1962 - val_mse: 0.1962 - val_mape: 313.7580 - val_mae: 0.4347 - 387ms/epoch - 7ms/step\n",
            "Epoch 7/500\n",
            "57/57 - 0s - loss: 0.0328 - mse: 0.0328 - mape: 64.5775 - mae: 0.1540 - val_loss: 0.2267 - val_mse: 0.2267 - val_mape: 333.9428 - val_mae: 0.4689 - 380ms/epoch - 7ms/step\n",
            "Epoch 8/500\n",
            "57/57 - 0s - loss: 0.0324 - mse: 0.0324 - mape: 63.8618 - mae: 0.1529 - val_loss: 0.2034 - val_mse: 0.2034 - val_mape: 319.8679 - val_mae: 0.4430 - 392ms/epoch - 7ms/step\n",
            "Epoch 9/500\n",
            "57/57 - 0s - loss: 0.0324 - mse: 0.0324 - mape: 63.6535 - mae: 0.1531 - val_loss: 0.2047 - val_mse: 0.2047 - val_mape: 310.6666 - val_mae: 0.4440 - 381ms/epoch - 7ms/step\n",
            "Epoch 10/500\n",
            "57/57 - 0s - loss: 0.0321 - mse: 0.0321 - mape: 64.8465 - mae: 0.1527 - val_loss: 0.1910 - val_mse: 0.1910 - val_mape: 303.6427 - val_mae: 0.4289 - 375ms/epoch - 7ms/step\n",
            "Epoch 11/500\n",
            "57/57 - 0s - loss: 0.0318 - mse: 0.0318 - mape: 63.7696 - mae: 0.1526 - val_loss: 0.1997 - val_mse: 0.1997 - val_mape: 315.8424 - val_mae: 0.4388 - 397ms/epoch - 7ms/step\n",
            "Epoch 12/500\n",
            "57/57 - 0s - loss: 0.0314 - mse: 0.0314 - mape: 62.9152 - mae: 0.1514 - val_loss: 0.1490 - val_mse: 0.1490 - val_mape: 280.3640 - val_mae: 0.3768 - 406ms/epoch - 7ms/step\n",
            "Epoch 13/500\n",
            "57/57 - 0s - loss: 0.0323 - mse: 0.0323 - mape: 64.9873 - mae: 0.1516 - val_loss: 0.1733 - val_mse: 0.1733 - val_mape: 308.5967 - val_mae: 0.4065 - 399ms/epoch - 7ms/step\n",
            "Epoch 14/500\n",
            "57/57 - 0s - loss: 0.0318 - mse: 0.0318 - mape: 64.4301 - mae: 0.1527 - val_loss: 0.1888 - val_mse: 0.1888 - val_mape: 313.5139 - val_mae: 0.4266 - 413ms/epoch - 7ms/step\n",
            "Epoch 15/500\n",
            "57/57 - 0s - loss: 0.0311 - mse: 0.0311 - mape: 63.0397 - mae: 0.1511 - val_loss: 0.2015 - val_mse: 0.2015 - val_mape: 323.0939 - val_mae: 0.4408 - 398ms/epoch - 7ms/step\n",
            "Epoch 16/500\n",
            "57/57 - 0s - loss: 0.0316 - mse: 0.0316 - mape: 64.8607 - mae: 0.1517 - val_loss: 0.1768 - val_mse: 0.1768 - val_mape: 282.6904 - val_mae: 0.4118 - 406ms/epoch - 7ms/step\n",
            "Epoch 17/500\n",
            "57/57 - 0s - loss: 0.0310 - mse: 0.0310 - mape: 65.8879 - mae: 0.1508 - val_loss: 0.1851 - val_mse: 0.1851 - val_mape: 299.3669 - val_mae: 0.4215 - 410ms/epoch - 7ms/step\n",
            "Epoch 18/500\n",
            "57/57 - 0s - loss: 0.0313 - mse: 0.0313 - mape: 61.9438 - mae: 0.1505 - val_loss: 0.1832 - val_mse: 0.1832 - val_mape: 316.2126 - val_mae: 0.4197 - 441ms/epoch - 8ms/step\n",
            "Epoch 19/500\n",
            "57/57 - 0s - loss: 0.0319 - mse: 0.0319 - mape: 66.5435 - mae: 0.1521 - val_loss: 0.1902 - val_mse: 0.1902 - val_mape: 325.8364 - val_mae: 0.4273 - 434ms/epoch - 8ms/step\n",
            "Epoch 20/500\n",
            "57/57 - 0s - loss: 0.0315 - mse: 0.0315 - mape: 66.2963 - mae: 0.1514 - val_loss: 0.2017 - val_mse: 0.2017 - val_mape: 295.8699 - val_mae: 0.4389 - 427ms/epoch - 7ms/step\n",
            "Epoch 21/500\n",
            "57/57 - 0s - loss: 0.0316 - mse: 0.0316 - mape: 64.5219 - mae: 0.1514 - val_loss: 0.2249 - val_mse: 0.2249 - val_mape: 338.9875 - val_mae: 0.4672 - 443ms/epoch - 8ms/step\n",
            "Epoch 22/500\n",
            "57/57 - 0s - loss: 0.0319 - mse: 0.0319 - mape: 63.4618 - mae: 0.1522 - val_loss: 0.1951 - val_mse: 0.1951 - val_mape: 312.4525 - val_mae: 0.4341 - 472ms/epoch - 8ms/step\n",
            "Epoch 23/500\n",
            "57/57 - 0s - loss: 0.0315 - mse: 0.0315 - mape: 64.3205 - mae: 0.1501 - val_loss: 0.2251 - val_mse: 0.2251 - val_mape: 349.2452 - val_mae: 0.4662 - 415ms/epoch - 7ms/step\n",
            "Epoch 24/500\n",
            "57/57 - 0s - loss: 0.0310 - mse: 0.0310 - mape: 64.9133 - mae: 0.1494 - val_loss: 0.1756 - val_mse: 0.1756 - val_mape: 317.3050 - val_mae: 0.4101 - 473ms/epoch - 8ms/step\n",
            "Epoch 25/500\n",
            "57/57 - 1s - loss: 0.0310 - mse: 0.0310 - mape: 64.8973 - mae: 0.1499 - val_loss: 0.1761 - val_mse: 0.1761 - val_mape: 304.8395 - val_mae: 0.4117 - 535ms/epoch - 9ms/step\n",
            "Epoch 26/500\n",
            "57/57 - 0s - loss: 0.0305 - mse: 0.0305 - mape: 63.1808 - mae: 0.1496 - val_loss: 0.1927 - val_mse: 0.1927 - val_mape: 293.4529 - val_mae: 0.4296 - 436ms/epoch - 8ms/step\n",
            "Epoch 27/500\n",
            "57/57 - 0s - loss: 0.0308 - mse: 0.0308 - mape: 63.8669 - mae: 0.1495 - val_loss: 0.1895 - val_mse: 0.1895 - val_mape: 309.9170 - val_mae: 0.4278 - 451ms/epoch - 8ms/step\n",
            "Epoch 28/500\n",
            "57/57 - 0s - loss: 0.0317 - mse: 0.0317 - mape: 63.4251 - mae: 0.1517 - val_loss: 0.1563 - val_mse: 0.1563 - val_mape: 288.2860 - val_mae: 0.3865 - 440ms/epoch - 8ms/step\n",
            "Epoch 29/500\n",
            "57/57 - 0s - loss: 0.0312 - mse: 0.0312 - mape: 63.3279 - mae: 0.1509 - val_loss: 0.1759 - val_mse: 0.1759 - val_mape: 308.5162 - val_mae: 0.4110 - 443ms/epoch - 8ms/step\n",
            "Epoch 30/500\n",
            "57/57 - 0s - loss: 0.0305 - mse: 0.0305 - mape: 64.2862 - mae: 0.1492 - val_loss: 0.1782 - val_mse: 0.1782 - val_mape: 301.0901 - val_mae: 0.4135 - 452ms/epoch - 8ms/step\n",
            "Epoch 31/500\n",
            "57/57 - 0s - loss: 0.0309 - mse: 0.0309 - mape: 64.3147 - mae: 0.1494 - val_loss: 0.2006 - val_mse: 0.2006 - val_mape: 319.2515 - val_mae: 0.4408 - 438ms/epoch - 8ms/step\n",
            "Epoch 32/500\n",
            "57/57 - 0s - loss: 0.0310 - mse: 0.0310 - mape: 63.0305 - mae: 0.1497 - val_loss: 0.1835 - val_mse: 0.1835 - val_mape: 300.6490 - val_mae: 0.4207 - 400ms/epoch - 7ms/step\n",
            "Epoch 33/500\n",
            "57/57 - 0s - loss: 0.0309 - mse: 0.0309 - mape: 62.1982 - mae: 0.1490 - val_loss: 0.1801 - val_mse: 0.1801 - val_mape: 291.8831 - val_mae: 0.4145 - 383ms/epoch - 7ms/step\n",
            "Epoch 34/500\n",
            "57/57 - 0s - loss: 0.0314 - mse: 0.0314 - mape: 62.2640 - mae: 0.1503 - val_loss: 0.1646 - val_mse: 0.1646 - val_mape: 283.8774 - val_mae: 0.3971 - 399ms/epoch - 7ms/step\n",
            "Epoch 35/500\n",
            "57/57 - 0s - loss: 0.0314 - mse: 0.0314 - mape: 63.5567 - mae: 0.1504 - val_loss: 0.1860 - val_mse: 0.1860 - val_mape: 285.6603 - val_mae: 0.4227 - 399ms/epoch - 7ms/step\n",
            "Epoch 36/500\n",
            "57/57 - 0s - loss: 0.0312 - mse: 0.0312 - mape: 65.5257 - mae: 0.1513 - val_loss: 0.1981 - val_mse: 0.1981 - val_mape: 322.6893 - val_mae: 0.4364 - 376ms/epoch - 7ms/step\n",
            "Epoch 37/500\n",
            "57/57 - 0s - loss: 0.0308 - mse: 0.0308 - mape: 61.1735 - mae: 0.1489 - val_loss: 0.1547 - val_mse: 0.1547 - val_mape: 263.3259 - val_mae: 0.3842 - 375ms/epoch - 7ms/step\n",
            "Epoch 38/500\n",
            "57/57 - 0s - loss: 0.0306 - mse: 0.0306 - mape: 62.9592 - mae: 0.1488 - val_loss: 0.1976 - val_mse: 0.1976 - val_mape: 325.7376 - val_mae: 0.4360 - 389ms/epoch - 7ms/step\n",
            "Epoch 39/500\n",
            "57/57 - 0s - loss: 0.0305 - mse: 0.0305 - mape: 62.9418 - mae: 0.1490 - val_loss: 0.1967 - val_mse: 0.1967 - val_mape: 312.2108 - val_mae: 0.4357 - 406ms/epoch - 7ms/step\n",
            "Epoch 40/500\n",
            "57/57 - 0s - loss: 0.0307 - mse: 0.0307 - mape: 65.0247 - mae: 0.1489 - val_loss: 0.1677 - val_mse: 0.1677 - val_mape: 291.4469 - val_mae: 0.4007 - 376ms/epoch - 7ms/step\n",
            "Epoch 41/500\n",
            "57/57 - 0s - loss: 0.0307 - mse: 0.0307 - mape: 65.0276 - mae: 0.1490 - val_loss: 0.1796 - val_mse: 0.1796 - val_mape: 295.1420 - val_mae: 0.4158 - 385ms/epoch - 7ms/step\n",
            "Epoch 42/500\n",
            "57/57 - 0s - loss: 0.0307 - mse: 0.0307 - mape: 62.1856 - mae: 0.1491 - val_loss: 0.1970 - val_mse: 0.1970 - val_mape: 318.6919 - val_mae: 0.4352 - 412ms/epoch - 7ms/step\n",
            "Epoch 43/500\n",
            "57/57 - 0s - loss: 0.0314 - mse: 0.0314 - mape: 63.0436 - mae: 0.1502 - val_loss: 0.1791 - val_mse: 0.1791 - val_mape: 298.2432 - val_mae: 0.4153 - 381ms/epoch - 7ms/step\n",
            "Epoch 44/500\n",
            "57/57 - 0s - loss: 0.0324 - mse: 0.0324 - mape: 62.5839 - mae: 0.1515 - val_loss: 0.1622 - val_mse: 0.1622 - val_mape: 287.9501 - val_mae: 0.3940 - 384ms/epoch - 7ms/step\n",
            "Epoch 45/500\n",
            "57/57 - 0s - loss: 0.0310 - mse: 0.0310 - mape: 61.3778 - mae: 0.1490 - val_loss: 0.1756 - val_mse: 0.1756 - val_mape: 300.9276 - val_mae: 0.4090 - 431ms/epoch - 8ms/step\n",
            "Epoch 46/500\n",
            "57/57 - 0s - loss: 0.0307 - mse: 0.0307 - mape: 65.4527 - mae: 0.1493 - val_loss: 0.1960 - val_mse: 0.1960 - val_mape: 324.5806 - val_mae: 0.4351 - 444ms/epoch - 8ms/step\n",
            "Epoch 47/500\n",
            "57/57 - 0s - loss: 0.0310 - mse: 0.0310 - mape: 63.7281 - mae: 0.1494 - val_loss: 0.1756 - val_mse: 0.1756 - val_mape: 282.9478 - val_mae: 0.4097 - 408ms/epoch - 7ms/step\n",
            "Epoch 48/500\n",
            "57/57 - 0s - loss: 0.0304 - mse: 0.0304 - mape: 63.5465 - mae: 0.1480 - val_loss: 0.1878 - val_mse: 0.1878 - val_mape: 306.4541 - val_mae: 0.4255 - 387ms/epoch - 7ms/step\n",
            "Epoch 49/500\n",
            "57/57 - 0s - loss: 0.0308 - mse: 0.0308 - mape: 64.8069 - mae: 0.1492 - val_loss: 0.1732 - val_mse: 0.1732 - val_mape: 316.5529 - val_mae: 0.4067 - 384ms/epoch - 7ms/step\n",
            "Epoch 50/500\n",
            "57/57 - 0s - loss: 0.0305 - mse: 0.0305 - mape: 60.8944 - mae: 0.1489 - val_loss: 0.1826 - val_mse: 0.1826 - val_mape: 311.8355 - val_mae: 0.4187 - 399ms/epoch - 7ms/step\n",
            "Epoch 51/500\n",
            "57/57 - 0s - loss: 0.0302 - mse: 0.0302 - mape: 63.4587 - mae: 0.1481 - val_loss: 0.2027 - val_mse: 0.2027 - val_mape: 321.7770 - val_mae: 0.4426 - 386ms/epoch - 7ms/step\n",
            "Epoch 52/500\n",
            "57/57 - 0s - loss: 0.0303 - mse: 0.0303 - mape: 62.8227 - mae: 0.1481 - val_loss: 0.2149 - val_mse: 0.2149 - val_mape: 321.0847 - val_mae: 0.4551 - 390ms/epoch - 7ms/step\n",
            "Epoch 53/500\n",
            "57/57 - 0s - loss: 0.0309 - mse: 0.0309 - mape: 65.6065 - mae: 0.1497 - val_loss: 0.2018 - val_mse: 0.2018 - val_mape: 323.8838 - val_mae: 0.4415 - 420ms/epoch - 7ms/step\n",
            "Epoch 54/500\n",
            "57/57 - 0s - loss: 0.0311 - mse: 0.0311 - mape: 63.0468 - mae: 0.1497 - val_loss: 0.1981 - val_mse: 0.1981 - val_mape: 311.0873 - val_mae: 0.4373 - 429ms/epoch - 8ms/step\n",
            "Epoch 55/500\n",
            "57/57 - 0s - loss: 0.0304 - mse: 0.0304 - mape: 62.2020 - mae: 0.1481 - val_loss: 0.1740 - val_mse: 0.1740 - val_mape: 290.4174 - val_mae: 0.4069 - 436ms/epoch - 8ms/step\n",
            "Epoch 56/500\n",
            "57/57 - 0s - loss: 0.0300 - mse: 0.0300 - mape: 63.2038 - mae: 0.1473 - val_loss: 0.1902 - val_mse: 0.1902 - val_mape: 316.4978 - val_mae: 0.4281 - 422ms/epoch - 7ms/step\n",
            "Epoch 57/500\n",
            "57/57 - 0s - loss: 0.0307 - mse: 0.0307 - mape: 63.6493 - mae: 0.1490 - val_loss: 0.1961 - val_mse: 0.1961 - val_mape: 312.2447 - val_mae: 0.4351 - 385ms/epoch - 7ms/step\n",
            "Epoch 58/500\n",
            "57/57 - 0s - loss: 0.0308 - mse: 0.0308 - mape: 60.9913 - mae: 0.1486 - val_loss: 0.1762 - val_mse: 0.1762 - val_mape: 304.7376 - val_mae: 0.4112 - 353ms/epoch - 6ms/step\n",
            "Epoch 59/500\n",
            "57/57 - 0s - loss: 0.0304 - mse: 0.0304 - mape: 61.8448 - mae: 0.1478 - val_loss: 0.1874 - val_mse: 0.1874 - val_mape: 312.1637 - val_mae: 0.4244 - 391ms/epoch - 7ms/step\n",
            "Epoch 60/500\n",
            "57/57 - 0s - loss: 0.0304 - mse: 0.0304 - mape: 62.8172 - mae: 0.1477 - val_loss: 0.1624 - val_mse: 0.1624 - val_mape: 285.7911 - val_mae: 0.3911 - 400ms/epoch - 7ms/step\n",
            "Epoch 61/500\n",
            "57/57 - 0s - loss: 0.0328 - mse: 0.0328 - mape: 63.4667 - mae: 0.1525 - val_loss: 0.1817 - val_mse: 0.1817 - val_mape: 309.3602 - val_mae: 0.4164 - 386ms/epoch - 7ms/step\n",
            "Epoch 62/500\n",
            "57/57 - 0s - loss: 0.0305 - mse: 0.0305 - mape: 63.4919 - mae: 0.1478 - val_loss: 0.1913 - val_mse: 0.1913 - val_mape: 304.9867 - val_mae: 0.4293 - 410ms/epoch - 7ms/step\n",
            "23/23 [==============================] - 1s 3ms/step\n",
            "lstm\n",
            "rmse: 2102.231497179847\n",
            "r2: 0.5668443402214411\n",
            "mae: 2083.6323891527686\n",
            "mape: 0.09753055397625883\n",
            "nse: 0.6961430713797473\n"
          ]
        }
      ]
    }
  ]
}